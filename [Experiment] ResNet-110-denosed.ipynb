{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91b8765a-636d-4e12-8906-147ef40fd46d",
   "metadata": {},
   "source": [
    "### Recreating the ResNet-110 experiment described in the [original paper](https://www.researchgate.net/publication/335844699_SEN12MS_-_A_Curated_D_of_Georeferenced_Multi-Spectral_Sentinel-12_Imagery_for_Deep_Learning_and_Data_Fusion)\n",
    "\n",
    "### *In that experiment we add two denosed bands from Sentinel-1\n",
    "\n",
    "#### Input\n",
    "- 64 × 64 Sentinel-2 and Sentinel-1 images from the summer subset\n",
    "- 12 bands: B2, B3, B4, B8, DVV, DVH, B5, B6, B7, B8a, B11, and B12.\n",
    "\n",
    "\n",
    "#### Label\n",
    "- Majority LCCS land use class from each of the 64 × 64 patches\n",
    "- 8 classes instead of 11: 20 and 25 combined; 30, 35, and 36 combined\n",
    "\n",
    "#### Training parameters\n",
    "- Categorical cross-entropy loss\n",
    "- Adam optimizer with 0.0005 starting learning rate\n",
    "- ReduceOnPlateau learning rate scheduler\n",
    "- Batch size: 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c50cd0bb-636c-4e52-a723-c083063a8d06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchmetrics\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from utils import sen12ms_dataLoader as sen12ms\n",
    "from utils import SEN12MSDataset_64x64subpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "365cbd4c-3ac0-4623-af5e-f49cfc324338",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = pathlib.Path('/home/dubrovin/Projects/Data/SEN12MS/')\n",
    "SEASON = sen12ms.Seasons.SUMMER\n",
    "\n",
    "assert DATASET_PATH.is_dir(), 'Incorect location for the dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5814a25-b275-43c9-9245-53f100b0e662",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResNet110(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ResNet110, self).__init__()\n",
    "        \n",
    "        self.resnet = models.resnet101()\n",
    "        self.resnet.conv1 = nn.Conv2d(12, 64, 7, 2, 3, bias=False)\n",
    "        self.resnet.fc = nn.Linear(2048, 8)\n",
    "        \n",
    "        # to transform the ResNet-101 to ResNet-110, add 3 extra bottleneck blocks\n",
    "        # each bottleneck block adds 3 layers, 101 + 3 * 3 = 110\n",
    "        for i in range(3):\n",
    "            self.resnet.layer3.add_module(f'extra_{i}', models.resnet.Bottleneck(1024, 256))\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.accuracy = torchmetrics.Accuracy()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        return x\n",
    "    \n",
    "    def setup(self, stage):\n",
    "        dataset = SEN12MSDataset_64x64subpatches(DATASET_PATH, SEASON)\n",
    "        n_val_examples = int(len(dataset) * 0.1)\n",
    "        splits = [len(dataset) - n_val_examples, n_val_examples]\n",
    "        self.train_data, self.val_data = torch.utils.data.random_split(dataset, splits)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        dataloader = torch.utils.data.DataLoader(self.train_data, batch_size=16, shuffle=True, num_workers=12, pin_memory=True)\n",
    "        return dataloader\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        dataloader = torch.utils.data.DataLoader(self.val_data, batch_size=16, num_workers=12, pin_memory=True)\n",
    "        return dataloader\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "#         x = x[:, 2:]\n",
    "        pred = self(x)\n",
    "        loss = self.criterion(pred, y)\n",
    "        accuracy = self.accuracy(pred.softmax(dim=1), y)\n",
    "        \n",
    "        batch_dict = {\n",
    "            'loss': loss,\n",
    "            'accuracy': accuracy,\n",
    "        }\n",
    "        \n",
    "        return batch_dict\n",
    "    \n",
    "    def training_epoch_end(self, train_step_outputs):\n",
    "        average_loss = torch.tensor([x['loss'] for x in train_step_outputs]).mean()\n",
    "        average_accuracy = torch.tensor([x['accuracy'] for x in train_step_outputs]).mean()\n",
    "        \n",
    "        # log to TebsorBoard\n",
    "        self.logger.experiment.add_scalar('Loss/train', average_loss, self.current_epoch)\n",
    "        self.logger.experiment.add_scalar('Accuracy/train', average_accuracy, self.current_epoch)\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        batch_dict = self.training_step(batch, batch_idx)\n",
    "        return batch_dict\n",
    "    \n",
    "    def validation_epoch_end(self, val_step_outputs):\n",
    "        average_loss = torch.tensor([x['loss'] for x in val_step_outputs]).mean()\n",
    "        average_accuracy = torch.tensor([x['accuracy'] for x in val_step_outputs]).mean()\n",
    "        \n",
    "        # log to TebsorBoard\n",
    "        self.logger.experiment.add_scalar('Loss/validation', average_loss, self.current_epoch)\n",
    "        self.logger.experiment.add_scalar('Accuracy/validation', average_accuracy, self.current_epoch)\n",
    "        \n",
    "        # log to the system for ReduceLROnPlateau and EarlyStopping / ModelCheckpoint\n",
    "        self.log('system/val_loss', average_loss)\n",
    "        self.log('system/val_acc', average_accuracy)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.0005)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "        return {'optimizer': optimizer, 'scheduler': scheduler, 'monitor': 'system/val_loss'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fd804db",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = pl.callbacks.EarlyStopping(\n",
    "    monitor='system/val_loss',\n",
    "    patience=4,\n",
    "    mode='min',\n",
    ")\n",
    "\n",
    "checkpoint_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='system/val_acc',\n",
    "    mode='max',\n",
    "    every_n_val_epochs=1,\n",
    "    dirpath='./best_models/',\n",
    "    filename=r'resnet110_den_v0_val_acc={system/val_acc:.2f}',\n",
    "    auto_insert_metric_name=False,\n",
    "    save_weights_only=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85cff755-1143-43f1-8271-a56cbd31f3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "Running in fast_dev_run mode: will run a full train, val and test loop using 1 batch(es).\n"
     ]
    }
   ],
   "source": [
    "model = ResNet110()\n",
    "logger = pl.loggers.TensorBoardLogger('runs', 'resnet110dn', default_hp_metric=False)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    logger=logger,\n",
    "    gpus=1, \n",
    "    callbacks=[stop_early, checkpoint_acc],\n",
    "    num_sanity_val_steps=0,\n",
    "    profiler='simple',\n",
    "    fast_dev_run=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "223a18bf-828c-4514-bfcd-46a7504eb2ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | resnet    | ResNet           | 45.9 M\n",
      "1 | criterion | CrossEntropyLoss | 0     \n",
      "2 | accuracy  | Accuracy         | 0     \n",
      "-----------------------------------------------\n",
      "45.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "45.9 M    Total params\n",
      "183.560   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|█████     | 1/2 [00:01<00:01,  1.45s/it, loss=2.34, v_num=]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████| 2/2 [00:02<00:00,  1.40s/it, loss=2.34, v_num=]\n",
      "Epoch 0: 100%|██████████| 2/2 [00:02<00:00,  1.45s/it, loss=2.34, v_num=]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FIT Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  4.7329         \t|  100 %          \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_training_epoch                 \t|  2.9059         \t|1              \t|  2.9059         \t|  61.399         \t|\n",
      "get_train_batch                    \t|  0.84596        \t|1              \t|  0.84596        \t|  17.874         \t|\n",
      "run_training_batch                 \t|  0.60089        \t|1              \t|  0.60089        \t|  12.696         \t|\n",
      "optimizer_step_and_closure_0       \t|  0.58728        \t|1              \t|  0.58728        \t|  12.409         \t|\n",
      "training_step_and_backward         \t|  0.55134        \t|1              \t|  0.55134        \t|  11.649         \t|\n",
      "model_forward                      \t|  0.50124        \t|1              \t|  0.50124        \t|  10.591         \t|\n",
      "training_step                      \t|  0.50081        \t|1              \t|  0.50081        \t|  10.582         \t|\n",
      "evaluation_step_and_end            \t|  0.057333       \t|1              \t|  0.057333       \t|  1.2114         \t|\n",
      "validation_step                    \t|  0.057036       \t|1              \t|  0.057036       \t|  1.2051         \t|\n",
      "backward                           \t|  0.048989       \t|1              \t|  0.048989       \t|  1.0351         \t|\n",
      "on_validation_batch_end            \t|  0.016939       \t|1              \t|  0.016939       \t|  0.35791        \t|\n",
      "on_train_batch_end                 \t|  0.0020081      \t|1              \t|  0.0020081      \t|  0.042428       \t|\n",
      "on_validation_start                \t|  0.0019876      \t|1              \t|  0.0019876      \t|  0.041996       \t|\n",
      "on_validation_end                  \t|  0.0013632      \t|1              \t|  0.0013632      \t|  0.028803       \t|\n",
      "on_train_start                     \t|  0.0011977      \t|1              \t|  0.0011977      \t|  0.025306       \t|\n",
      "on_train_epoch_start               \t|  0.00091752     \t|1              \t|  0.00091752     \t|  0.019386       \t|\n",
      "on_train_end                       \t|  0.00086172     \t|1              \t|  0.00086172     \t|  0.018207       \t|\n",
      "cache_result                       \t|  1.4155e-05     \t|24             \t|  0.00033972     \t|  0.0071779      \t|\n",
      "on_train_epoch_end                 \t|  0.00032783     \t|1              \t|  0.00032783     \t|  0.0069266      \t|\n",
      "on_batch_start                     \t|  0.00011863     \t|1              \t|  0.00011863     \t|  0.0025066      \t|\n",
      "on_validation_batch_start          \t|  0.00010514     \t|1              \t|  0.00010514     \t|  0.0022215      \t|\n",
      "on_train_batch_start               \t|  4.3742e-05     \t|1              \t|  4.3742e-05     \t|  0.00092422     \t|\n",
      "validation_step_end                \t|  3.902e-05      \t|1              \t|  3.902e-05      \t|  0.00082445     \t|\n",
      "on_batch_end                       \t|  2.9355e-05     \t|1              \t|  2.9355e-05     \t|  0.00062024     \t|\n",
      "on_after_backward                  \t|  2.8902e-05     \t|1              \t|  2.8902e-05     \t|  0.00061067     \t|\n",
      "on_before_zero_grad                \t|  2.6052e-05     \t|1              \t|  2.6052e-05     \t|  0.00055045     \t|\n",
      "on_epoch_start                     \t|  1.2432e-05     \t|2              \t|  2.4864e-05     \t|  0.00052535     \t|\n",
      "on_epoch_end                       \t|  1.0807e-05     \t|2              \t|  2.1614e-05     \t|  0.00045668     \t|\n",
      "training_step_end                  \t|  2.0514e-05     \t|1              \t|  2.0514e-05     \t|  0.00043344     \t|\n",
      "on_validation_epoch_end            \t|  1.7155e-05     \t|1              \t|  1.7155e-05     \t|  0.00036246     \t|\n",
      "on_validation_epoch_start          \t|  1.7021e-05     \t|1              \t|  1.7021e-05     \t|  0.00035963     \t|\n",
      "on_fit_start                       \t|  1.5389e-05     \t|1              \t|  1.5389e-05     \t|  0.00032515     \t|\n",
      "on_train_dataloader                \t|  9.718e-06      \t|1              \t|  9.718e-06      \t|  0.00020533     \t|\n",
      "on_before_accelerator_backend_setup\t|  9.405e-06      \t|1              \t|  9.405e-06      \t|  0.00019872     \t|\n",
      "on_val_dataloader                  \t|  5.814e-06      \t|1              \t|  5.814e-06      \t|  0.00012284     \t|\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
