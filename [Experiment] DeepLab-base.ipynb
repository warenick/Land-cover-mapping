{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91b8765a-636d-4e12-8906-147ef40fd46d",
   "metadata": {},
   "source": [
    "### DeepLab basic experiment\n",
    "\n",
    "#### Input\n",
    "- Full-sized 256x256 Sentinel-2 and Sentinel-1 images from the summer subset\n",
    "- 12 bands: B2, B3, B4, B8, DVV, DVH, B5, B6, B7, B8a, B11, and B12.\n",
    "\n",
    "\n",
    "#### Label\n",
    "- LCCS land use images\n",
    "- 8 classes instead of 11: 20 and 25 combined; 30, 35, and 36 combined\n",
    "\n",
    "#### Training parameters\n",
    "- Categorical cross-entropy loss\n",
    "- Adam optimizer with 0.0001 starting learning rate\n",
    "- ReduceOnPlateau learning rate scheduler\n",
    "- Batch size: 4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c50cd0bb-636c-4e52-a723-c083063a8d06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchmetrics\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import models\n",
    "from utils import SEN12MSDataset\n",
    "from utils import sen12ms_dataLoader as sen12ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "365cbd4c-3ac0-4623-af5e-f49cfc324338",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = pathlib.Path('/home/dubrovin/Projects/Data/SEN12MS/')\n",
    "SEASON = sen12ms.Seasons.SUMMER\n",
    "\n",
    "assert DATASET_PATH.is_dir(), 'Incorect location for the dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5814a25-b275-43c9-9245-53f100b0e662",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DeepLab_base(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(DeepLab, self).__init__()\n",
    "        \n",
    "        self.net = models.DeepLab(backbone='resnet', pretrained_backbone=True, output_stride=16, sync_bn=False, n_in=12, num_classes=8)\n",
    "            \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.accuracy = torchmetrics.Accuracy()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x\n",
    "    \n",
    "    def setup(self, stage):\n",
    "        dataset = SEN12MSDataset(DATASET_PATH, SEASON)\n",
    "        n_val_examples = int(len(dataset) * 0.1)\n",
    "        splits = [len(dataset) - n_val_examples, n_val_examples]\n",
    "        self.train_data, self.val_data = torch.utils.data.random_split(dataset, splits)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        dataloader = torch.utils.data.DataLoader(self.train_data, batch_size=4, shuffle=True, num_workers=12, pin_memory=True)\n",
    "        return dataloader\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        dataloader = torch.utils.data.DataLoader(self.val_data, batch_size=4, num_workers=12, pin_memory=True)\n",
    "        return dataloader\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "#         x = x[:, 2:]\n",
    "        pred = self(x)\n",
    "        loss = self.criterion(pred, y)\n",
    "        self.pred_accuracy = accuracy\n",
    "        try:\n",
    "            accuracy = self.accuracy(pred.softmax(dim=1), y)\n",
    "        except:\n",
    "            accuracy = self.pred_accuracy\n",
    "        \n",
    "        batch_dict = {\n",
    "            'loss': loss,\n",
    "            'accuracy': accuracy,\n",
    "        }\n",
    "        \n",
    "        return batch_dict\n",
    "    \n",
    "    def training_epoch_end(self, train_step_outputs):\n",
    "        average_loss = torch.tensor([x['loss'] for x in train_step_outputs]).mean()\n",
    "        average_accuracy = torch.tensor([x['accuracy'] for x in train_step_outputs]).mean()\n",
    "        \n",
    "        # log to TebsorBoard\n",
    "        self.logger.experiment.add_scalar('Loss/train', average_loss, self.current_epoch)\n",
    "        self.logger.experiment.add_scalar('Accuracy/train', average_accuracy, self.current_epoch)\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        batch_dict = self.training_step(batch, batch_idx)\n",
    "        return batch_dict\n",
    "    \n",
    "    def validation_epoch_end(self, val_step_outputs):\n",
    "        average_loss = torch.tensor([x['loss'] for x in val_step_outputs]).mean()\n",
    "        average_accuracy = torch.tensor([x['accuracy'] for x in val_step_outputs]).mean()\n",
    "        \n",
    "        # log to TebsorBoard\n",
    "        self.logger.experiment.add_scalar('Loss/validation', average_loss, self.current_epoch)\n",
    "        self.logger.experiment.add_scalar('Accuracy/validation', average_accuracy, self.current_epoch)\n",
    "        \n",
    "        # log to the system for ReduceLROnPlateau and EarlyStopping / ModelCheckpoint\n",
    "        self.log('system/val_loss', average_loss)\n",
    "        self.log('system/val_acc', average_accuracy)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.0001)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "        return {'optimizer': optimizer, 'scheduler': scheduler, 'monitor': 'system/val_loss'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fd804db",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = pl.callbacks.EarlyStopping(\n",
    "    monitor='system/val_loss',\n",
    "    patience=4,\n",
    "    mode='min',\n",
    ")\n",
    "\n",
    "checkpoint_acc = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='system/val_acc',\n",
    "    mode='max',\n",
    "    every_n_val_epochs=1,\n",
    "    dirpath='./best_models/',\n",
    "    filename=r'deeplab_base_v0_val_acc={system/val_acc:.2f}',\n",
    "    auto_insert_metric_name=False,\n",
    "    save_weights_only=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85cff755-1143-43f1-8271-a56cbd31f3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "/home/dubrovin/.miniforge3/envs/pytorch/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: GPU available but not used. Set the gpus flag in your trainer `Trainer(gpus=1)` or script `--gpus=1`.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Running in fast_dev_run mode: will run a full train, val and test loop using 1 batch(es).\n"
     ]
    }
   ],
   "source": [
    "model = DeepLab_base()\n",
    "logger = pl.loggers.TensorBoardLogger('runs', 'deeplab_base', default_hp_metric=False)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    logger=logger,\n",
    "    gpus=0, \n",
    "    callbacks=[stop_early, checkpoint_acc],\n",
    "    profiler='simple',\n",
    "    num_sanity_val_steps=0,\n",
    "    fast_dev_run=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "223a18bf-828c-4514-bfcd-46a7504eb2ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | densenet  | FCDenseNet103    | 9.3 M \n",
      "1 | criterion | CrossEntropyLoss | 0     \n",
      "2 | accuracy  | Accuracy         | 0     \n",
      "-----------------------------------------------\n",
      "9.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "9.3 M     Total params\n",
      "37.291    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|█████     | 1/2 [00:21<00:21, 21.21s/it, loss=2.18, v_num=]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████| 2/2 [00:30<00:00, 15.13s/it, loss=2.18, v_num=]\n",
      "Epoch 0: 100%|██████████| 2/2 [00:30<00:00, 15.15s/it, loss=2.18, v_num=]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FIT Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  30.545         \t|  100 %          \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_training_epoch                 \t|  30.308         \t|1              \t|  30.308         \t|  99.225         \t|\n",
      "run_training_batch                 \t|  18.638         \t|1              \t|  18.638         \t|  61.017         \t|\n",
      "optimizer_step_and_closure_0       \t|  18.637         \t|1              \t|  18.637         \t|  61.014         \t|\n",
      "training_step_and_backward         \t|  18.453         \t|1              \t|  18.453         \t|  60.414         \t|\n",
      "backward                           \t|  10.394         \t|1              \t|  10.394         \t|  34.029         \t|\n",
      "model_forward                      \t|  8.0575         \t|1              \t|  8.0575         \t|  26.379         \t|\n",
      "training_step                      \t|  8.0572         \t|1              \t|  8.0572         \t|  26.378         \t|\n",
      "evaluation_step_and_end            \t|  7.1831         \t|1              \t|  7.1831         \t|  23.517         \t|\n",
      "validation_step                    \t|  7.1829         \t|1              \t|  7.1829         \t|  23.516         \t|\n",
      "get_train_batch                    \t|  2.5647         \t|1              \t|  2.5647         \t|  8.3966         \t|\n",
      "on_validation_end                  \t|  0.004406       \t|1              \t|  0.004406       \t|  0.014425       \t|\n",
      "on_validation_start                \t|  0.0037536      \t|1              \t|  0.0037536      \t|  0.012289       \t|\n",
      "on_train_batch_end                 \t|  0.0036467      \t|1              \t|  0.0036467      \t|  0.011939       \t|\n",
      "on_validation_batch_end            \t|  0.0029663      \t|1              \t|  0.0029663      \t|  0.0097113      \t|\n",
      "on_train_start                     \t|  0.0014234      \t|1              \t|  0.0014234      \t|  0.0046602      \t|\n",
      "on_train_epoch_start               \t|  0.00086115     \t|1              \t|  0.00086115     \t|  0.0028193      \t|\n",
      "on_train_end                       \t|  0.00084201     \t|1              \t|  0.00084201     \t|  0.0027566      \t|\n",
      "on_train_epoch_end                 \t|  0.00033147     \t|1              \t|  0.00033147     \t|  0.0010852      \t|\n",
      "cache_result                       \t|  1.3104e-05     \t|24             \t|  0.00031449     \t|  0.0010296      \t|\n",
      "on_validation_batch_start          \t|  0.00013737     \t|1              \t|  0.00013737     \t|  0.00044973     \t|\n",
      "on_batch_start                     \t|  8.0003e-05     \t|1              \t|  8.0003e-05     \t|  0.00026192     \t|\n",
      "on_after_backward                  \t|  3.8529e-05     \t|1              \t|  3.8529e-05     \t|  0.00012614     \t|\n",
      "on_before_zero_grad                \t|  3.7832e-05     \t|1              \t|  3.7832e-05     \t|  0.00012386     \t|\n",
      "on_train_batch_start               \t|  3.0529e-05     \t|1              \t|  3.0529e-05     \t|  9.9948e-05     \t|\n",
      "on_epoch_end                       \t|  1.5234e-05     \t|2              \t|  3.0468e-05     \t|  9.9748e-05     \t|\n",
      "on_epoch_start                     \t|  1.4414e-05     \t|2              \t|  2.8828e-05     \t|  9.4379e-05     \t|\n",
      "validation_step_end                \t|  2.4486e-05     \t|1              \t|  2.4486e-05     \t|  8.0164e-05     \t|\n",
      "on_fit_start                       \t|  1.9897e-05     \t|1              \t|  1.9897e-05     \t|  6.514e-05      \t|\n",
      "on_batch_end                       \t|  1.7213e-05     \t|1              \t|  1.7213e-05     \t|  5.6353e-05     \t|\n",
      "on_validation_epoch_end            \t|  1.6445e-05     \t|1              \t|  1.6445e-05     \t|  5.3839e-05     \t|\n",
      "on_validation_epoch_start          \t|  1.3484e-05     \t|1              \t|  1.3484e-05     \t|  4.4145e-05     \t|\n",
      "training_step_end                  \t|  1.2683e-05     \t|1              \t|  1.2683e-05     \t|  4.1522e-05     \t|\n",
      "on_train_dataloader                \t|  1.1708e-05     \t|1              \t|  1.1708e-05     \t|  3.833e-05      \t|\n",
      "on_before_accelerator_backend_setup\t|  9.261e-06      \t|1              \t|  9.261e-06      \t|  3.0319e-05     \t|\n",
      "on_val_dataloader                  \t|  6.7819e-06     \t|1              \t|  6.7819e-06     \t|  2.2203e-05     \t|\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
