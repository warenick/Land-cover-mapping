{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b17333f-60a5-4e71-8446-fdc82329cd6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# in Colab, rasterio needs to be installed\n",
    "# !pip install rasterio\n",
    "\n",
    "import random\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# download and extract the dataset sample\n",
    "# if not pathlib.Path('../SEN12MS_sample').is_dir():\n",
    "#     !gdown --id 1GKHIPhhfjutCbb3LhJ0tgjxDvIuDO7tr\n",
    "#     !tar -zxf SEN12MS_sample.tgz\n",
    "#     !rm SEN12MS_sample.tgz\n",
    "sys.path.insert(1,\"../\")\n",
    "import utils.sen12ms_dataLoader as sen12ms\n",
    "sys.path.remove(\"../\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c314b85b-be3a-4c30-907e-672b1bb79e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def scale(data):\n",
    "    min_ = data.min()\n",
    "    max_ = data.max()\n",
    "    return (data - min_) / (max_ - min_+1e-8), min_, max_\n",
    "\n",
    "def scale_batch(data):\n",
    "    mins = []\n",
    "    maxs = []\n",
    "    for i in range(len(data)):\n",
    "        d, min_, max_ = scale(data[i,0])\n",
    "        data[i,0] = d\n",
    "        mins.append(min_)\n",
    "        maxs.append(max_)\n",
    "        \n",
    "    return data, mins, maxs\n",
    "        \n",
    "def descale(data, min_, max_, ):\n",
    "    return min_+ data * (max_ - min_+1e-8)\n",
    "\n",
    "def descale_batch(data, mins, maxs):\n",
    "    for i in range(len(data)):\n",
    "        data[i,0] = descale(data[i,0],mins[i],maxs[i])\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "danish-causing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the data loader\n",
    "dataset = sen12ms.SEN12MSDataset(base_dir='../SEN12MS_sample') # Change path\n",
    "# collect all patches\n",
    "seasons = sen12ms.Seasons.ALL\n",
    "# get a dictionary {scene_id: patch_ids} for the whole season\n",
    "patch_unique_ids = []\n",
    "for season in seasons.value:\n",
    "    season_ids = dataset.get_season_ids(season=season)\n",
    "    for scene_id, patch_ids in season_ids.items():\n",
    "        for patch_id in patch_ids:\n",
    "            patch_unique_ids.append((season, scene_id, patch_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "underlying-tours",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# load model\n",
    "# ----------------------------------------\n",
    "from models.network_unet import UNetRes as net\n",
    "\n",
    "model_pool = 'model_zoo'             # fixed\n",
    "model_name = 'drunet_gray'  # set denoiser model, 'drunet_gray' | 'drunet_color'\n",
    "model_path = os.path.join(model_pool, model_name+'.pth')\n",
    "\n",
    "n_channels = 1                       # 1 for grayscale image\n",
    "if 'color' in model_name:\n",
    "    n_channels = 3                   # 3 for color image\n",
    "task_current = 'dn'                  # 'dn' for denoising\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = net(in_nc=n_channels+1, out_nc=n_channels, nc=[64, 128, 256, 512], nb=4, act_mode='R', downsample_mode=\"strideconv\", upsample_mode=\"convtranspose\")\n",
    "model.load_state_dict(torch.load(model_path), strict=True)\n",
    "model.eval()\n",
    "for k, v in model.named_parameters():\n",
    "    v.requires_grad = False\n",
    "model = model.to(device)\n",
    "print('Model path: {:s}'.format(model_path))\n",
    "number_parameters = sum(map(lambda x: x.numel(), model.parameters()))\n",
    "print('Params number: {}'.format(number_parameters))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-maine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s1, bb = dataset.get_patch(patch_unique_ids[0][0], patch_unique_ids[0][1], patch_unique_ids[2][2], sen12ms.S1Bands.ALL)\n",
    "# with_original = np.concatenate((s1,s1))\n",
    "# dataset.save_patch((with_original,bb),patch_unique_ids[0][0], patch_unique_ids[0][1], patch_unique_ids[2][2], sen12ms.S1Bands.ALLD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporated-intro",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1, dbb = dataset.get_patch(patch_unique_ids[0][0], patch_unique_ids[0][1], patch_unique_ids[2][2], sen12ms.S1Bands.ALLD)\n",
    "# ds1.shape\n",
    "# dbb\n",
    "# ds1 == s1\n",
    "# print(bb,dbb) # <-- losses bounds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-temperature",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# \n",
    "noise_level_model = 70.\n",
    "\n",
    "\n",
    "for patch in tqdm(patch_unique_ids):\n",
    "    #     get patch\n",
    "    s1, bb = dataset.get_patch(patch[0], patch[1], patch[2], sen12ms.S1Bands.ALL)\n",
    "    #     convert to tensor\n",
    "    din = torch.tensor(s1[None], device = device, dtype = torch.float32)\n",
    "    #     split channels\n",
    "    #     din.shape: torch.Size([bs, 2, 256, 256]) - > din.shape: torch.Size([bs*2, 1, 256, 256])\n",
    "    din = din.reshape([din.shape[0]*2,1,din.shape[2],din.shape[3]])\n",
    "    #     scaling   \n",
    "    din, mean, std = scale_batch(din)\n",
    "    #     add random normal noise\n",
    "    din += torch.randn(din.shape,device=device,dtype = torch.float32)*noise_level_model/255.\n",
    "    #     Add noise map\n",
    "    #     din.shape: torch.Size([bs*2, 1, 256, 256]) - > din.shape: torch.Size([bs*2, 2, 256, 256])\n",
    "    nose_map = torch.tensor([noise_level_model/255.],device=device, dtype = torch.float32).repeat(din.shape[0], 1, din.shape[2], din.shape[3])\n",
    "    din = torch.cat((din,nose_map), dim=1)\n",
    "    \n",
    "    #     denose\n",
    "    denoised = model(din)\n",
    "    \n",
    "    #     return original scale\n",
    "    denoised = descale_batch(denoised, mean, std)\n",
    "    #     return original shape\n",
    "    denoised = denoised.reshape([int(denoised.shape[0]/2),2,denoised.shape[2],denoised.shape[3]]).to('cpu').numpy()\n",
    "    #     concatinate bands with original\n",
    "    with_original = np.concatenate(( s1, denoised.squeeze()))\n",
    "    #     save data\n",
    "    dataset.save_patch((with_original,bb),patch[0], patch[1], patch[2], sen12ms.S1Bands.ALLD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-moscow",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
